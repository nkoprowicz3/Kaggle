{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept: model each store as a time series, then divide the store predictions by items. \n",
    "\n",
    "After looking at the data a bit, it looks like item sales are random. Sales at the store level, however, show seasonality, and look more like time series. Can we make predictions at the store level and then break those into item level based on each item's overall sales?\n",
    "\n",
    "Note that by taking the time series approach, there's a lot of data I *didn't* utilize (price, events, etc.). So it would be an interesting next step to see how those variables could be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "1. Import, melt data\n",
    "2. For each store, find the ratio at which each item contributes to overall sales\n",
    "3. Build an ARMA model for each store and decompose predictions based on (2)\n",
    "4. Utilize the notebook recently posted by Vopani (https://www.kaggle.com/rohanrao/m5-how-to-get-your-public-lb-score-rank) to estimate public leaderboard score\n",
    "5. Submit predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "sample = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n",
    "evaluation = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\n",
    "\n",
    "# Break into the training and validation set\n",
    "\n",
    "df_train = evaluation.iloc[:, :-28]\n",
    "df_valid = evaluation.iloc[:, -28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting the dataframe will make it so days are rows, rather than columns. It is needed later when sales are aggregated by stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe\n",
    "\n",
    "d_cols = ['d_' + str(i + 1) for i in range(1913)]\n",
    "\n",
    "ts_df = pd.melt(frame = df_train, \n",
    "                     id_vars = ['id', 'item_id', 'cat_id', 'store_id'],\n",
    "                     var_name = 'd',\n",
    "                     value_vars = d_cols,\n",
    "                     value_name = 'sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. For each store, find how much each item contributes to overall sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate total sales by store\n",
    "\n",
    "store_level = ts_df[['store_id', 'sales']].groupby('store_id').agg('sum')\n",
    "\n",
    "# Aggregate total sales by store and item\n",
    "\n",
    "store_item_level = ts_df[['store_id', 'item_id', 'sales']].groupby(['store_id', 'item_id']).agg('sum')\n",
    "\n",
    "store_level = store_level.reset_index()\n",
    "store_item_level = store_item_level.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each store, figure out how much each item contributes to overall sales\n",
    "\n",
    "totals = store_level.merge(store_item_level, on = 'store_id', how = 'left')\n",
    "totals['ratio'] = totals.apply(lambda row: row['sales_y'] / row['sales_x'], axis = 1)\n",
    "\n",
    "# Make two copies of this dataframe, which will u\n",
    "\n",
    "totals['id'] = totals['item_id'] + '_' + totals['store_id'] + '_' + 'evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a dataframe that we'll ultimately use for the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two copies of the dataframe\n",
    "totals1 = totals.copy()\n",
    "totals2 = totals.copy()\n",
    "\n",
    "# Add an 'id' column\n",
    "totals1['id'] = totals1['item_id'] + '_' + totals1['store_id'] + '_' + 'evaluation'\n",
    "totals2['id'] = totals2['item_id'] + '_' + totals2['store_id'] + '_' + 'validation'\n",
    "\n",
    "# Concatenate vertically\n",
    "totals = pd.concat([totals2, totals1], axis = 0)\n",
    "totals = totals.reset_index().drop('index', axis = 1)\n",
    "\n",
    "join_df = sample.merge(totals, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build an ARMA model for each store and decompose predictions based on (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the stores and all the items\n",
    "stores = df_train['store_id'].unique()\n",
    "items = df_train['item_id'].unique()\n",
    "\n",
    "# Get a list of the days we're predicting for\n",
    "f_cols = ['F' + str(i + 1) for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the magic happens!\n",
    "\n",
    "The orders of the ARMA model are hard-coded, found through experimenting. This notebook isn't about the theory of time series as much as the approach of building a larger time series and decomposing it, so I'll leave out the details of experimenting.\n",
    "\n",
    "Do note that it takes a minute to run. Commenting out the '%%capture' at the top of the cell will give status updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# surpress output from fitting ARMA models\n",
    "\n",
    "# Make an ARMA model for each store\n",
    "\n",
    "for store in stores:\n",
    "    \n",
    "    print('starting store: ' + store)\n",
    "    \n",
    "    # Generate a time series by grouping the sales data by store\n",
    "    store_data = ts_df[ts_df['store_id'] == store]\n",
    "    store_data_sales = store_data[['d', 'sales']].groupby('d').agg(sum)\n",
    "    store_data_sales = store_data_sales.reset_index()\n",
    "    store_data_sales['d'] = store_data_sales['d'].apply(lambda x: int(x.split('_')[1]))\n",
    "    store_data_sales = store_data_sales.sort_values('d')\n",
    "    ts = store_data_sales['sales']\n",
    "    ts.index = store_data_sales['d']\n",
    "\n",
    "    # Make an ARMA model\n",
    "    if store in ['WI_1', 'WI_3']:\n",
    "        order = (7, 0, 2)\n",
    "    elif store == 'WI_2':\n",
    "        order = (6, 0, 2)\n",
    "    else:\n",
    "        order = (10, 0, 2)\n",
    "    \n",
    "    model = ARIMA(ts[-100:], order = order)\n",
    "    results_AR = model.fit(disp = -1)\n",
    "\n",
    "    # b holds the predictions. Note that we predict for 56 additional days (28 validation and 28 evaluation)\n",
    "    a = results_AR.predict(start = 0, end = len(ts[-100:]) + 56 - 2)\n",
    "    b = a[-56:]\n",
    "    b.index = ts[-56:].index + 56 \n",
    "    \n",
    "    # Add the predictions to our dataframe that we'll ultimately use for submission\n",
    "    df = join_df[(join_df['store_id'] == store) & (join_df['id'].str.contains('validation'))]\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        print('working on row ' + str(i))\n",
    "        join_df.loc[i, f_cols] = [b.values[j]*row['ratio'] for j in range(28)]\n",
    "        join_df.loc[i + 30490, f_cols] = [b.values[j + 28]*row['ratio'] for j in range(28)]\n",
    "        \n",
    "# Supress output (from ARMA model generation)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utilize the notebook recently posted by Vopani (https://www.kaggle.com/rohanrao/m5-how-to-get-your-public-lb-score-rank) to estimate public leaderboard score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is taken from the notebook above, and the evaluation metric was eventually defined here: https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "## evaluation metric\n",
    "## from https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834 and edited to get scores at all levels\n",
    "class WRMSSEEvaluator(object):\n",
    "\n",
    "    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n",
    "        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n",
    "        train_target_columns = train_y.columns.tolist()\n",
    "        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        train_df['all_id'] = 0  # for lv1 aggregation\n",
    "\n",
    "        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n",
    "        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n",
    "\n",
    "        if not all([c in valid_df.columns for c in id_columns]):\n",
    "            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "\n",
    "        self.weight_columns = weight_columns\n",
    "        self.id_columns = id_columns\n",
    "        self.valid_target_columns = valid_target_columns\n",
    "\n",
    "        weight_df = self.get_weight_df()\n",
    "\n",
    "        self.group_ids = (\n",
    "            'all_id',\n",
    "            'state_id',\n",
    "            'store_id',\n",
    "            'cat_id',\n",
    "            'dept_id',\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            'item_id',\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "        )\n",
    "\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids)):\n",
    "            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n",
    "            scale = []\n",
    "            for _, row in train_y.iterrows():\n",
    "                series = row.values[np.argmax(row.values != 0):]\n",
    "                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n",
    "            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n",
    "            setattr(self, f'lv{i + 1}_train_df', train_y)\n",
    "            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n",
    "\n",
    "            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n",
    "            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n",
    "\n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n",
    "        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n",
    "        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n",
    "        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n",
    "\n",
    "        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n",
    "        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n",
    "        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n",
    "        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n",
    "        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n",
    "        return weight_df\n",
    "\n",
    "    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n",
    "        valid_y = getattr(self, f'lv{lv}_valid_df')\n",
    "        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n",
    "        scale = getattr(self, f'lv{lv}_scale')\n",
    "        return (score / scale).map(np.sqrt)\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n",
    "\n",
    "        group_ids = []\n",
    "        all_scores = []\n",
    "        for i, group_id in enumerate(self.group_ids):\n",
    "            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n",
    "            weight = getattr(self, f'lv{i + 1}_weight')\n",
    "            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n",
    "            group_ids.append(group_id)\n",
    "            all_scores.append(lv_scores.sum())\n",
    "\n",
    "        return group_ids, all_scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public LB rank\n",
    "def get_lb_rank(score):\n",
    "    \"\"\"\n",
    "    Get rank on public LB as of 2020-05-31 23:59:59\n",
    "    \"\"\"\n",
    "    df_lb = pd.read_csv(\"../input/m5-accuracy-final-public-lb/m5-forecasting-accuracy-publicleaderboard-rank.csv\")\n",
    "\n",
    "    return (df_lb.Score <= score).sum() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f593b9519241c097fed9ce11ce9763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## reading data\n",
    "df_calendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\n",
    "df_prices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\n",
    "df_sample_submission = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\n",
    "df_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n",
    "\n",
    "evaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation predictions are in the first 30490 rows of our prediction dataframe\n",
    "\n",
    "preds_valid = join_df.loc[:30490,].drop(['store_id', 'sales_x', 'item_id', 'sales_y', 'ratio'], axis = 1)\n",
    "preds_valid = preds_valid[preds_valid.id.str.contains(\"validation\")]\n",
    "preds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\n",
    "preds_valid.rename(columns = {\n",
    "    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n",
    "    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n",
    "    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n",
    "    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n",
    "}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for group all_id: 1.09082\n",
      "Score for group state_id: 1.09327\n",
      "Score for group store_id: 1.1165\n",
      "Score for group cat_id: 1.10929\n",
      "Score for group dept_id: 1.23243\n",
      "Score for group ['state_id', 'cat_id']: 1.1404\n",
      "Score for group ['state_id', 'dept_id']: 1.22651\n",
      "Score for group ['store_id', 'cat_id']: 1.17216\n",
      "Score for group ['store_id', 'dept_id']: 1.23069\n",
      "Score for group item_id: 1.32549\n",
      "Score for group ['item_id', 'state_id']: 1.14111\n",
      "Score for group ['item_id', 'store_id']: 0.98756\n",
      "\n",
      "Public LB Score: 1.15552\n",
      "Public LB Rank: 4013\n"
     ]
    }
   ],
   "source": [
    "## evaluating random submission\n",
    "groups, scores = evaluator.score(preds_valid)\n",
    "\n",
    "score_public_lb = np.mean(scores)\n",
    "score_public_rank = get_lb_rank(score_public_lb)\n",
    "\n",
    "for i in range(len(groups)):\n",
    "    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n",
    "\n",
    "print(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")\n",
    "print(f\"Public LB Rank: {score_public_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submit predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = join_df.drop(['store_id', 'sales_x', 'item_id', 'sales_y', 'ratio'], axis = 1)\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for looking at my kernel! I didn't have as much time as I would have liked to for this one, but I tried to get something together quickly :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "45f593b9519241c097fed9ce11ce9763": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5f76a8c1a2a34b1a92ab2a0a4b281994",
        "IPY_MODEL_5dace732e54d406082378867e70744cc"
       ],
       "layout": "IPY_MODEL_a35583f7f0b54400ac79a43185a70080"
      }
     },
     "52e103c3042447db884ce9d065e3ac06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "5dace732e54d406082378867e70744cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bca5607bb83b47c6b4b812b5bb6114ce",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a5443f75099044bb9f6cc8832680d2a5",
       "value": " 12/12 [00:22&lt;00:00,  1.85s/it]"
      }
     },
     "5f76a8c1a2a34b1a92ab2a0a4b281994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a2bb3b00ab141ec9f64a41852d8aa0d",
       "max": 12,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52e103c3042447db884ce9d065e3ac06",
       "value": 12
      }
     },
     "9a2bb3b00ab141ec9f64a41852d8aa0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a35583f7f0b54400ac79a43185a70080": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5443f75099044bb9f6cc8832680d2a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bca5607bb83b47c6b4b812b5bb6114ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

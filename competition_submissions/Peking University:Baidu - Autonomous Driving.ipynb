{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom tqdm import tqdm#_notebook as tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom functools import reduce\nimport os\nfrom scipy.optimize import minimize\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom torchvision import transforms, utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '../input/pku-autonomous-driving/'\nos.listdir(PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(PATH + 'train.csv')\ntest = pd.read_csv(PATH + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"camera_params = np.array([[2304.5479, 0, 1686.2379],\n                         [0, 2305.8757, 1354.9849],\n                         [0, 0, 1]], dtype = np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will take a prediction string from\n# the training dataset and output an array of \n# dictionaries, where each dictionary contains \n# the information for a car in the given picture\n\ndef str2coords(input_str):\n    names=['id', 'yaw', 'pitch', 'roll', 'x', 'y', 'z']\n    coords = []\n    for l in np.array(input_str.split()).reshape([-1, 7]):\n        coords.append(dict(zip(names, l.astype('float'))))\n        #if 'id' in coords[-1]:\n         #   coords[-1]['id'] = int(coords[-1]['id'])\n    #coords.pop('id')\n    return coords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function takes the prediction string\n# and then does the necessary math so that we\n# get the x, y coordinates of the PIXEL corresponding\n# to other cars in the image\n\ndef get_img_coords(input_str):\n    coords = str2coords(input_str)\n    \n    xs = [c['x'] for c in coords]\n    ys = [c['y'] for c in coords]\n    zs = [c['z'] for c in coords]\n    P = np.array(list(zip(xs, ys, zs))).T # Array where row1 is x's, row2 is y's, row 3 is z's\n    \n    img_p = np.dot(camera_params, P).T # This gives the pixel coordinates, multpilied by the z-coordinate\n    \n    # get rid of the z-coordinate constant by dividing it out\n    img_p[:, 0] /= img_p[:, 2] \n    img_p[:, 1] /= img_p[:, 2] \n    \n    img_xs = img_p[:, 0]\n    img_ys = img_p[:, 1]\n    img_zs = img_p[:, 2] # z = Distance from the camera\n    \n    # return the x and y pixel coordinates for each car in the picture\n    return img_xs, img_ys\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_WIDTH = 1024\nIMG_HEIGHT = IMG_WIDTH // 16*5\nMODEL_SCALE = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(img):\n    \n    # Cut the image in half vertically, since cars are only\n    # in the bottom half of the image\n    img = img[img.shape[0]//2:] \n    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n    return (img / 255).astype('float32')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An example"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,14))\nplt.imshow(cv2.imread(PATH + 'train_images/' + train.iloc[0]['ImageId'] + '.jpg'))\nplt.scatter(*get_img_coords(train.iloc[0]['PredictionString']), color='red', s=100);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_img_coords(train['PredictionString'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mask_and_regr(img, labels):\n    mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE], dtype='float32')\n    #mask = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WITDH // MODEL_SCALE], dtype = 'float32')\n    regr_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n    regr = np.zeros([IMG_HEIGHT // MODEL_SCALE, IMG_WIDTH // MODEL_SCALE, 6], dtype = 'float32')\n    coords = str2coords(labels)\n    xs, ys = get_img_coords(labels)\n    \n    for x, y, regr_dict in zip(xs, ys, coords):\n        x, y = y, x \n        x = (x - img.shape[0] // 2) * IMG_HEIGHT / (img.shape[0] // 2) / MODEL_SCALE\n        x = np.round(x).astype('int')\n        y = y * IMG_WIDTH / (img.shape[1]) / MODEL_SCALE\n        y = np.round(y).astype('int')\n        if x >= 0 and x < IMG_HEIGHT // MODEL_SCALE and y >= 0 and y < IMG_WIDTH // MODEL_SCALE:\n            mask[x, y] = 1\n            #regr_dict = _regr_preprocess(regr_dict, flip)\n            regr_dict.pop('id')\n            regr[x, y] = [regr_dict[n] for n in sorted(regr_dict)]\n            \n    return mask, regr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a mask for all the cars in the image,\n# rather than the x and y pixel coordinates (why??)\n\ndef get_mask(img, labels):\n    mask = np.zeros()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_dir = PATH + 'train_images/{}.jpg'\ntest_images_dir = PATH + 'test_images/{}.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_dev = train_test_split(train, test_size = 0.01, random_state = 42)\ndf_test = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PyTorch works with *Datasets*.  Here, we need to define a custom dataset.  \n\nCustom datasets should override the __len__ and __getitem__ methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CarDataset(Dataset):\n    def __init__(self, dataframe, root_dir):\n        self.df = dataframe\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        idx, labels = self.df.values[idx]\n        img_name = self.root_dir.format(idx)\n        #print(labels)\n        img0 = cv2.imread(img_name)\n        img = preprocess_image(img0)\n        #labels = str2coords(labels)\n        mask, regr = get_mask_and_regr(img0, labels)\n        regr = np.rollaxis(regr, 2, 0)\n        return [img, mask, regr]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CarDataset(df_train, train_images_dir)\ndev_dataset = CarDataset(df_dev, train_images_dir)\ntest_dataset = CarDataset(df_test, test_images_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 4\n\ntrain_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\ndev_loader = DataLoader(dataset = dev_dataset, batch_size = BATCH_SIZE, shuffle = False)\ntest_loader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need to make a mas and regr so that each output is the same size"},{"metadata":{"trusted":true},"cell_type":"code","source":"img0 = cv2.imread(PATH + 'train_images/' + train['ImageId'][6] + '.jpg')\nimg = preprocess_image(img0)\n\nmask, regr = get_mask_and_regr(img0, train['PredictionString'][6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"points = np.argwhere(regr > 0)\nd = points[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in points:\n    print(a[0], a[1])\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\nplt.title('Processed image')\nplt.imshow(img)\nplt.show()\n\nplt.figure(figsize=(16,16))\nplt.title('Yaw values')\nplt.imshow(regr[:,:,-2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 2),\n            #nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size = 5, stride = 1, padding = 2),\n            #nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size = 5, stride = 1, padding = 2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\n        \n        self.drop_out = nn.Dropout()\n        \n        self.layer6 = nn.Sequential(\n            nn.Conv2d(128, 6, 1),\n            nn.ReLU())   \n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        #out = self.layer4(out)\n        #out = self.layer5(out)\n        out = self.drop_out(out)\n        out = self.layer6(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def criterion(prediction, mask, regr):\n   \n    loss = (torch.abs(prediction - regr).sum(1) * mask).sum(1).sum(1) / mask.sum(1).sum(1)\n    #torch.abs(prediction.to(device) - regr.to(device)).sum(1).sum(1).sum(1)\n    return loss.mean(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ConvNet().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train()\n\ndef train_model(epoch, history = None):\n    for batch_idx, (img_batch, mask_batch, regr_batch) in enumerate(tqdm(train_loader)):\n        \n        img_batch = img_batch.float().to(device)\n        #regr_batch = regr_batch.permute(0, 3, 1, 2)\n        regr_batch = regr_batch.to(device)\n        mask_batch = mask_batch.to(device)\n        output = model(img_batch.permute(0, 3, 1, 2))\n        output = output.to(device)\n        \n        loss = criterion(output, mask_batch, regr_batch)\n        optimizer.zero_grad()\n        if history is not None:\n            history.loc[epoch + batch_idx / len(train_loader), 'train_loss'] = loss.data.cpu().numpy()\n\n        loss.backward()\n\n        optimizer.step()\n\n        print('Train Epoch: {} \\tLR: {:.6f}\\tLoss: {:.6f}'.format(\n            epoch,\n            optimizer.state_dict()['param_groups'][0]['lr'],\n            loss.data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, mask, regr = [ x[0] for x in iter(train_loader).next() ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nprint(mask.shape)\nprint(regr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport gc\n\nhistory = pd.DataFrame()\n\nfor epoch in range(n_epochs):\n    torch.cuda.empty_cache()\n    gc.collect()\n    train_model(epoch, history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_coords(prediction):\n    logits = prediction[0]\n    points = np.argwhere(logits > 0)\n    col_names = ['x', 'y', 'z', 'yaw', 'pitch', 'roll']\n    coords = []\n    for r, c in points:\n        regr_dict = dict(zip(col_names, prediction[:, r, c]))\n        coords.append(regr_dict)\n        coords[-1]['confidence'] = 1 / (1 + np.exp(-logits[r, c]))\n        \n    return coords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def coords2str(coords, names=['yaw', 'pitch', 'roll', 'x', 'y', 'z', 'confidence']):\n    s = []\n    for c in coords:\n        for n in names:\n            s.append(str(c.get(n, 0)))\n    return ' '.join(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\ntest_loader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=False, num_workers=4)\n\nmodel.eval()\n\nfor img, _, _, in tqdm(test_loader):\n    with torch.no_grad():\n        output = model(img.permute(0, 3, 1, 2).to(device))\n        output = output.permute(0, 2, 3, 1)\n    output = output.data.cpu().numpy()\n    for out in output:\n        coords = extract_coords(out)\n        s = coords2str(coords)\n        predictions.append(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(PATH + 'sample_submission.csv')\ntest['PredictionString'] = predictions\ntest.to_csv('predictions.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[0, 'PredictionString']","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}